# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Load the dataset
data = pd.read_csv("/Users/spencer.fargey/lighthouselabs/tdsf-midterm/df_linear_model.csv")

# X is initialized as all columns except description.sold_price
X = data.drop('description.sold_price', axis=1)
# Initialize y as description.sold_price
y = data['description.sold_price']

# Define the lower and upper percentiles for capping
lower_percentile = 0.01  # 1st percentile
upper_percentile = 0.99  # 99th percentile

# Get the values at these percentiles
lower_bound = y.quantile(lower_percentile)
upper_bound = y.quantile(upper_percentile)

# Cap the outliers in the target variable
y_capped = y.clip(lower_bound, upper_bound)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y_capped, test_size=0.2, shuffle=True, random_state=42)

# Optionally, scale the features
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize Ridge regression model
ridge_model = Ridge(alpha=1.0)  # You can tune alpha later if needed

# Set up K-Fold cross-validation
kf = KFold(n_splits=10, shuffle=True, random_state=42)

# Perform K-Fold cross-validation with R^2 scoring
cv_scores_r2 = cross_val_score(ridge_model, X_train_scaled, y_train, cv=kf, scoring='r2')

# Calculate the average R^2 score from cross-validation
average_r2_cv = cv_scores_r2.mean()

# Perform K-Fold cross-validation with negative mean squared error (MSE) scoring
cv_scores_mse = cross_val_score(ridge_model, X_train_scaled, y_train, cv=kf, scoring='neg_mean_squared_error')

# Calculate the average RMSE from cross-validation
average_rmse_cv = np.sqrt(-cv_scores_mse.mean())

# Fit the model on the entire training set
ridge_model.fit(X_train_scaled, y_train)

# Make predictions on the test set
y_train_pred = ridge_model.predict(X_train_scaled)
y_test_pred = ridge_model.predict(X_test_scaled)

# Evaluate the model
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

mae_train = mean_absolute_error(y_train, y_train_pred)
mae_test = mean_absolute_error(y_test, y_test_pred)

mse_train = mean_squared_error(y_train, y_train_pred)
mse_test = mean_squared_error(y_test, y_test_pred)

rmse_train = np.sqrt(mse_train)
rmse_test = np.sqrt(mse_test)

# Print the results
print(f'Average CV R^2: {average_r2_cv}')
print(f'Average CV RMSE: {average_rmse_cv}\n')

print(f'Train R^2: {r2_train}\nTest R^2:  {r2_test}\n')
print(f'Train MAE: {mae_train}\nTest MAE:  {mae_test}\n')
print(f'Train MSE: {mse_train}\nTest MSE:  {mse_test}\n')
print(f'Train RMSE: {rmse_train}\nTest RMSE:  {rmse_test}')
